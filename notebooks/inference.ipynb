{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from phenaki_pytorch import CViViT, MaskGit, Phenaki\n",
    "\n",
    "cvivit = CViViT(\n",
    "    dim = 512,\n",
    "    codebook_size = 65536,\n",
    "    image_size = (256, 128),  # video with rectangular screen allowed\n",
    "    patch_size = 32,\n",
    "    temporal_patch_size = 2,\n",
    "    spatial_depth = 4,\n",
    "    temporal_depth = 4,\n",
    "    dim_head = 64,\n",
    "    heads = 8\n",
    ")\n",
    "\n",
    "model_path = os.path.expanduser(f\"~/.cache/Appimate\")\n",
    "cvivit.load(model_path)\n",
    "# cvivit.load('/path/to/trained/cvivit.pt')\n",
    "maskgit = MaskGit(\n",
    "    num_tokens = 5000,\n",
    "    max_seq_len = 1024,\n",
    "    dim = 512,\n",
    "    dim_context = 768,\n",
    "    depth = 6,\n",
    ")\n",
    "\n",
    "phenaki = Phenaki(\n",
    "    cvivit = cvivit,\n",
    "    maskgit = maskgit\n",
    ").cuda()\n",
    "\n",
    "\n",
    "\n",
    "video = phenaki.sample(texts = 'a squirrel examines an acorn', num_frames = 17, cond_scale = 5.) # (1, 3, 17, 256, 128)\n",
    "# so in the paper, they do not really achieve 2 minutes of coherent video\n",
    "# at each new scene with new text conditioning, they condition on the previous K frames\n",
    "# you can easily achieve this with this framework as so\n",
    "\n",
    "video_prime = video[:, :, -3:] # (1, 3, 3, 256, 128) # say K = 3\n",
    "\n",
    "video_next = phenaki.sample(texts = 'a cat watches the squirrel from afar', prime_frames = video_prime, num_frames = 14) # (1, 3, 14, 256, 128)\n",
    "\n",
    "# the total video\n",
    "\n",
    "entire_video = torch.cat((video, video_next), dim = 2) # (1, 3, 17 + 14, 256, 128)\n",
    "\n",
    "# and so on..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
