{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/LuthandoMaqondo/phenaki-pytorch/blob/main/notebooks/training.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mount the drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    WORKING_DIR = '.'\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    WORKING_DIR = '/content/drive/MyDrive/Colab Notebooks'\n",
    "    drive.mount('/content/drive',  force_remount=True)\n",
    "if IN_COLAB:\n",
    "    sys.path.insert(0, WORKING_DIR)\n",
    "else:\n",
    "    # The actual code is one level higher in folder depth/structure, so we're elevating this notebook.\n",
    "    sys.path.insert(0,f\".{WORKING_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: phenaki-pytorch in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (0.4.2)\n",
      "Requirement already satisfied: accelerate in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (0.24.1)\n",
      "Requirement already satisfied: beartype in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (0.17.0)\n",
      "Requirement already satisfied: einops>=0.7 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (0.7.0)\n",
      "Requirement already satisfied: ema-pytorch>=0.2.2 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (0.3.3)\n",
      "Requirement already satisfied: opencv-python in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (4.8.1.78)\n",
      "Requirement already satisfied: pillow in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (10.0.1)\n",
      "Requirement already satisfied: numpy in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (1.26.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (0.1.99)\n",
      "Requirement already satisfied: torch>=1.6 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (2.1.0)\n",
      "Requirement already satisfied: torchtyping in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (0.1.4)\n",
      "Requirement already satisfied: torchvision in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (0.16.0)\n",
      "Requirement already satisfied: transformers>=4.20.1 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (4.34.0)\n",
      "Requirement already satisfied: tqdm in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (4.65.0)\n",
      "Requirement already satisfied: vector-quantize-pytorch>=1.11.8 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from phenaki-pytorch) (1.12.17)\n",
      "Requirement already satisfied: filelock in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from torch>=1.6->phenaki-pytorch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from torch>=1.6->phenaki-pytorch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from torch>=1.6->phenaki-pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from torch>=1.6->phenaki-pytorch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from torch>=1.6->phenaki-pytorch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from torch>=1.6->phenaki-pytorch) (2023.9.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from transformers>=4.20.1->phenaki-pytorch) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from transformers>=4.20.1->phenaki-pytorch) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from transformers>=4.20.1->phenaki-pytorch) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from transformers>=4.20.1->phenaki-pytorch) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from transformers>=4.20.1->phenaki-pytorch) (2.29.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from transformers>=4.20.1->phenaki-pytorch) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from transformers>=4.20.1->phenaki-pytorch) (0.4.0)\n",
      "Requirement already satisfied: einx[torch]>=0.1.3 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from vector-quantize-pytorch>=1.11.8->phenaki-pytorch) (0.1.3)\n",
      "Requirement already satisfied: psutil in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from accelerate->phenaki-pytorch) (5.9.0)\n",
      "Requirement already satisfied: typeguard>=2.11.1 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from torchtyping->phenaki-pytorch) (4.1.5)\n",
      "Requirement already satisfied: frozendict in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from einx[torch]>=0.1.3->vector-quantize-pytorch>=1.11.8->phenaki-pytorch) (2.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from jinja2->torch>=1.6->phenaki-pytorch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from requests->transformers>=4.20.1->phenaki-pytorch) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from requests->transformers>=4.20.1->phenaki-pytorch) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from requests->transformers>=4.20.1->phenaki-pytorch) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from requests->transformers>=4.20.1->phenaki-pytorch) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/luthandomaqondo/miniconda3/lib/python3.11/site-packages (from sympy->torch>=1.6->phenaki-pytorch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install phenaki-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train teh AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mphenaki_pytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CViViT, CViViTTrainer\n\u001b[1;32m      3\u001b[0m cvivit \u001b[38;5;241m=\u001b[39m CViViT(\n\u001b[1;32m      4\u001b[0m     dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m      5\u001b[0m     codebook_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m65536\u001b[39m,\n\u001b[1;32m      6\u001b[0m     image_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m      7\u001b[0m     patch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      8\u001b[0m     temporal_patch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      9\u001b[0m     spatial_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     10\u001b[0m     temporal_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     11\u001b[0m     dim_head \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     12\u001b[0m     heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m---> 13\u001b[0m )\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     15\u001b[0m data_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mWORKING_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/datasets/Appimate/train\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m IN_COLAB \u001b[38;5;28;01melse\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~/.cache/Appimate/train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CViViTTrainer(\n\u001b[1;32m     17\u001b[0m     cvivit,\n\u001b[1;32m     18\u001b[0m     folder \u001b[38;5;241m=\u001b[39m data_folder,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     num_train_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:918\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: t\u001b[38;5;241m.\u001b[39mcuda(device))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:918\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: t\u001b[38;5;241m.\u001b[39mcuda(device))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from phenaki_pytorch import CViViT, CViViTTrainer, MaskGit, Phenaki\n",
    "\n",
    "cvivit = CViViT(\n",
    "    dim = 512,\n",
    "    codebook_size = 65536,\n",
    "    image_size = 256,\n",
    "    patch_size = 32,\n",
    "    temporal_patch_size = 2,\n",
    "    spatial_depth = 4,\n",
    "    temporal_depth = 4,\n",
    "    dim_head = 64,\n",
    "    heads = 8\n",
    ").cuda()\n",
    "\n",
    "data_folder = os.path.expanduser(f\"{WORKING_DIR}/datasets/Appimate/train\") if IN_COLAB else os.path.expanduser(f\"~/.cache/Appimate/train\")\n",
    "trainer = CViViTTrainer(\n",
    "    cvivit,\n",
    "    folder = data_folder,\n",
    "    batch_size = 4,\n",
    "    grad_accum_every = 4,\n",
    "    train_on_images = False,  # you can train on images first, before fine tuning on video, for sample efficiency\n",
    "    use_ema = False,          # recommended to be turned on (keeps exponential moving averaged cvivit) unless if you don't have enough resources\n",
    "    num_train_steps = 10\n",
    ")\n",
    "# trainer.train()               # reconstructions and checkpoints will be saved periodically to ./results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Phenaki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskgit = MaskGit(\n",
    "    num_tokens = 5000,\n",
    "    max_seq_len = 1024,\n",
    "    dim = 512,\n",
    "    dim_context = 768,\n",
    "    depth = 6,\n",
    ")\n",
    "\n",
    "phenaki = Phenaki(\n",
    "    cvivit = cvivit,\n",
    "    maskgit = maskgit\n",
    ").cuda()\n",
    "\n",
    "videos = torch.randn(3, 3, 17, 256, 128).cuda() # (batch, channels, frames, height, width)\n",
    "mask = torch.ones((3, 17)).bool().cuda() # [optional] (batch, frames) - allows for co-training videos of different lengths as well as video and images in the same batch\n",
    "\n",
    "num_ephochs = 10\n",
    "for epoch in range(0, num_ephochs):\n",
    "    texts = [\n",
    "        'a whale breaching from afar',\n",
    "        'young girl blowing out candles on her birthday cake',\n",
    "        'fireworks with blue and green sparkles'\n",
    "    ]\n",
    "\n",
    "    loss = phenaki(videos, texts = texts, video_frame_mask = mask)\n",
    "    loss.backward()\n",
    "    # do the above for many steps, then ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = phenaki.sample(texts = 'a squirrel examines an acorn', num_frames = 17, cond_scale = 5.) # (1, 3, 17, 256, 128)\n",
    "\n",
    "# so in the paper, they do not really achieve 2 minutes of coherent video\n",
    "# at each new scene with new text conditioning, they condition on the previous K frames\n",
    "# you can easily achieve this with this framework as so\n",
    "\n",
    "video_prime = video[:, :, -3:] # (1, 3, 3, 256, 128) # say K = 3\n",
    "video_next = phenaki.sample(texts = 'a cat watches the squirrel from afar', prime_frames = video_prime, num_frames = 14) # (1, 3, 14, 256, 128)\n",
    "\n",
    "# the total video\n",
    "entire_video = torch.cat((video, video_next), dim = 2) # (1, 3, 17 + 14, 256, 128)\n",
    "\n",
    "# and so on..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
